{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the environment\n",
    "import time, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data \n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "print train_images.shape\n",
    "print len(train_labels)\n",
    "print test_images.shape\n",
    "print len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Preprocess data\n",
    "#plt.figure()\n",
    "#plt.imshow(train_images[0])\n",
    "#plt.colorbar()\n",
    "#plt.gca().grid(False)\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an simple model\n",
    "def createModel(lr,reg):\n",
    "    model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            keras.layers.Dense(128, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(reg)),\n",
    "            keras.layers.Dense(10, activation=tf.nn.softmax, kernel_regularizer=regularizers.l2(reg))\n",
    "    ])\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(lr), \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tool for visualizeing quick scan\n",
    "def visQuickScan(results):\n",
    "    import math\n",
    "    x_scatter = [math.log10(x[0]) for x in results]\n",
    "    y_scatter = [math.log10(x[1]) for x in results]\n",
    "\n",
    "    # plot training accuracy\n",
    "    marker_size = 100\n",
    "    colors = [results[x][0] for x in results]\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.scatter(x_scatter, y_scatter, marker_size, c=colors)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('log learning rate')\n",
    "    plt.ylabel('log regularization')\n",
    "    plt.title('training accuracy')\n",
    "\n",
    "    # plot test accuracy\n",
    "    colors = [results[x][1] for x in results] # default size of markers is 20\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.scatter(x_scatter, y_scatter, marker_size, c=colors)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('log learning rate')\n",
    "    plt.ylabel('log regularization')\n",
    "    plt.title(' test accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quick scan loop to find out the entry point\n",
    "def quickScan(lr_range=[-3.0,-4.0],reg_range=[1,0],epoch=5,batch_size=10,sample=10):\n",
    "    # init\n",
    "    results = {}\n",
    "    learning_rates = lr_range\n",
    "    regularization_strengths = reg_range\n",
    "    best_val = -1\n",
    "    best_lr, best_reg = 0, 0\n",
    "    \n",
    "    # Timing\n",
    "    tic = time.time()\n",
    "    for i in range(sample):\n",
    "        lr = 10**np.random.uniform(learning_rates[0],learning_rates[1])\n",
    "        reg = 10**np.random.uniform(regularization_strengths[0],regularization_strengths[1])\n",
    "        print 'No.', str(i)\n",
    "        print 'lr:', str(lr)\n",
    "        print 'reg:', str(reg)\n",
    "        \n",
    "        # model\n",
    "        model = createModel(lr,reg)\n",
    "        #model.summary()\n",
    "        \n",
    "        # training\n",
    "        model.fit(train_images, train_labels,\n",
    "                  validation_data = (test_images,test_labels),\n",
    "                  epochs=epoch,\n",
    "                  batch_size=batch_size,\n",
    "                  shuffle=True)\n",
    "        \n",
    "        # evaluate result\n",
    "        train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
    "        test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "        print('Train accuracy:', train_acc)\n",
    "        print('Test accuracy:', test_acc)\n",
    "        \n",
    "        # record\n",
    "        results[(lr,reg)] = (train_acc,test_acc)\n",
    "        if best_val < test_acc:\n",
    "            print 'Found Better model!!!'\n",
    "            best_val = test_acc\n",
    "            best_lr = lr\n",
    "            best_reg = reg\n",
    "            model.save_weights('./weight/myBestweight')\n",
    "    \n",
    "    toc = time.time()\n",
    "    print 'Total Training: computed in %fs' % (toc - tic)\n",
    "    print 'Best Validation Record %.5f' % (best_val)\n",
    "    print 'Best Validation learning rate %.10f' % (best_lr)\n",
    "    print 'Best Validation regularization %.10f' % (best_reg)\n",
    "    \n",
    "    # Visaulize the distribution\n",
    "    visQuickScan(results)\n",
    "    \n",
    "    return best_lr, best_reg\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the quick scan loop with the random learning rate & L2\n",
    "best_lr, best_reg = quickScan(lr_range=[-3.0,-4.0],reg_range=[-4.0,-5.0],epoch=5,batch_size=10,sample=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best model to predict label\n",
    "\n",
    "# load weight\n",
    "model = createModel(best_lr, best_reg)\n",
    "model.load_weights('./weight/myBestweight')\n",
    "\n",
    "train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# predict\n",
    "predictions = model.predict(test_images)\n",
    "print predictions[0]\n",
    "print np.argmax(predictions[0])\n",
    "print test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tensorboard\n",
    "tensorboard = TensorBoard(log_dir='./Graph', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model to train longer (marathon)\n",
    "# Load weight, lr, reg\n",
    "# Add checkpoint & tensorboard metrics\n",
    "\n",
    "def marathon(lr,reg,epoch,batch_size,tensorboard):\n",
    "    # Timing\n",
    "    tic = time.time()\n",
    "        \n",
    "    # model\n",
    "    model = createModel(lr,reg)\n",
    "    model.load_weights('./weight/myBestweight')\n",
    "    #model.summary()\n",
    "        \n",
    "    # training\n",
    "    model.fit(train_images, train_labels,\n",
    "              validation_data = (test_images,test_labels),\n",
    "              epochs=epoch,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=True,\n",
    "              callbacks=[tensorboard])\n",
    "        \n",
    "    # evaluate result\n",
    "    train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "    print('Train accuracy:', train_acc)\n",
    "    print('Test accuracy:', test_acc)\n",
    "        \n",
    "\n",
    "    model.save_weights('./weight/marathonWeight')\n",
    "    \n",
    "    toc = time.time()\n",
    "    print 'Total Training: computed in %fs' % (toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon(best_lr,best_reg,epoch=1000,batch_size=10,tensorboard=tensorboard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
